{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import copy\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "from utils.utils import *\n",
    "from pathlib import Path\n",
    "from newloader import Crack_loader\n",
    "from model.TransMUNet import TransMUNet\n",
    "from torch.utils.data import DataLoader\n",
    "from ptflops import get_model_complexity_info\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "setup_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_classes = int(config['number_classes'])\n",
    "input_channels = 3\n",
    "best_val_loss  = np.inf\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "data_tra_path = config['path_to_tradata']\n",
    "data_val_path = config['path_to_valdata']\n",
    "\n",
    "DIR_IMG_tra  = os.path.join(data_tra_path, 'images')\n",
    "DIR_MASK_tra = os.path.join(data_tra_path, 'masks')\n",
    "\n",
    "DIR_IMG_val  = os.path.join(data_val_path, 'images')\n",
    "DIR_MASK_val = os.path.join(data_val_path, 'masks')\n",
    "\n",
    "img_names_tra  = [path.name for path in Path(DIR_IMG_tra).glob('*.jpg')]\n",
    "mask_names_tra = [path.name for path in Path(DIR_MASK_tra).glob('*.png')]\n",
    "\n",
    "img_names_val  = [path.name for path in Path(DIR_IMG_val).glob('*.jpg')]\n",
    "mask_names_val = [path.name for path in Path(DIR_MASK_val).glob('*.png')]\n",
    "\n",
    "train_dataset = Crack_loader(img_dir=DIR_IMG_tra, img_fnames=img_names_tra, mask_dir=DIR_MASK_tra, mask_fnames=mask_names_tra, isTrain=True)\n",
    "valid_dataset = Crack_loader(img_dir=DIR_IMG_val, img_fnames=img_names_val, mask_dir=DIR_MASK_val, mask_fnames=mask_names_val, resize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_dataset:300\n",
      "valiant_dataset:237\n"
     ]
    }
   ],
   "source": [
    "print(f'train_dataset:{len(train_dataset)}')\n",
    "print(f'valiant_dataset:{len(valid_dataset)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To work with small dataset, take first 10 samples\n",
    "train_dataset = torch.utils.data.Subset(train_dataset, range(20))\n",
    "valid_dataset = torch.utils.data.Subset(valid_dataset, range(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_dataset:20\n",
      "valiant_dataset:20\n"
     ]
    }
   ],
   "source": [
    "print(f'train_dataset:{len(train_dataset)}')\n",
    "print(f'valiant_dataset:{len(valid_dataset)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flops:  112.49 GMac params:  2.03 M\n"
     ]
    }
   ],
   "source": [
    "train_loader  = DataLoader(train_dataset, batch_size = int(config['batch_size_tr']), shuffle= True,  drop_last=True)\n",
    "val_loader    = DataLoader(valid_dataset, batch_size = int(config['batch_size_va']), shuffle= False, drop_last=True)\n",
    "\n",
    "# Net = TransMUNet(n_classes = number_classes)\n",
    "Net = TransMUNet(in_channels=input_channels, out_channels=number_classes, nhead=int(config['nhead']), num_layers=int(config['num_layers']))\n",
    "flops, params = get_model_complexity_info(Net, (3, 256, 256), as_strings=True, print_per_layer_stat=False)\n",
    "print('flops: ', flops, 'params: ', params)\n",
    "message = 'flops:%s, params:%s' % (flops, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "Net = Net.to(device)\n",
    "# load pretrained model\n",
    "if int(config['pretrained']):\n",
    "    Net.load_state_dict(torch.load(config['saved_model'], map_location='cpu')['model_weights'])\n",
    "    best_val_loss = torch.load(config['saved_model'], map_location='cpu')['val_loss']\n",
    "\n",
    "optimizer = optim.Adam(Net.parameters(), lr= float(config['lr']))\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', factor = 0.5, patience = config['patience'])\n",
    "criteria  = DiceBCELoss()\n",
    "\n",
    "# visual\n",
    "visualizer = Visualizer(isTrain=True)\n",
    "log_name = os.path.join('./checkpoints', config['loss_filename'])\n",
    "with open(log_name, \"a\") as log_file:\n",
    "            log_file.write('%s\\n' % message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of msk_pred: torch.Size([2, 256, 256])\n",
      "Shape of msk: torch.Size([2, 256, 256])\n",
      "Shape of msk_pred: torch.Size([2, 256, 256])\n",
      "Shape of msk: torch.Size([2, 256, 256])\n",
      "Shape of msk_pred: torch.Size([2, 256, 256])\n",
      "Shape of msk: torch.Size([2, 256, 256])\n",
      "Shape of msk_pred: torch.Size([2, 256, 256])\n",
      "Shape of msk: torch.Size([2, 256, 256])\n",
      "Shape of msk_pred: torch.Size([2, 256, 256])\n",
      "Shape of msk: torch.Size([2, 256, 256])\n",
      "Shape of msk_pred: torch.Size([2, 256, 256])\n",
      "Shape of msk: torch.Size([2, 256, 256])\n",
      "Shape of msk_pred: torch.Size([2, 256, 256])\n",
      "Shape of msk: torch.Size([2, 256, 256])\n",
      "Shape of msk_pred: torch.Size([2, 256, 256])\n",
      "Shape of msk: torch.Size([2, 256, 256])\n",
      "Shape of msk_pred: torch.Size([2, 256, 256])\n",
      "Shape of msk: torch.Size([2, 256, 256])\n",
      "Shape of msk_pred: torch.Size([2, 256, 256])\n",
      "Shape of msk: torch.Size([2, 256, 256])\n",
      "val_mode\n",
      "validation on epoch>> 1, mean tloss>> 0.991363 \n",
      "New best loss, saving...,best_val_loss=0.991363\n",
      "Trainig phase finished\n"
     ]
    }
   ],
   "source": [
    "for ep in range(int(config['epochs'])):\n",
    "    # # train\n",
    "    Net.train()\n",
    "    epoch_loss = 0\n",
    "    for itter, batch in enumerate(train_loader):\n",
    "        img = batch['image'].to(device, dtype=torch.float)\n",
    "        msk = batch['mask'].to(device)\n",
    "        boundary = batch['boundary'].to(device)\n",
    "        mask_type = torch.float32 if Net.n_classes == 1 else torch.long\n",
    "        msk = msk.to(device=device, dtype=mask_type)\n",
    "        boundary = boundary.to(device=device, dtype=mask_type)\n",
    "        msk_pred, B = Net(img,istrain=True)\n",
    "        # Ensure msk has the correct dimensions\n",
    "        if msk.shape[1] == 1:\n",
    "            msk = msk.squeeze(1)  # Remove channel dimension if it's 1\n",
    "\n",
    "        # Print shapes of predictions and ground truth for debugging\n",
    "        print(f\"Shape of msk_pred: {msk_pred.shape}\")\n",
    "        print(f\"Shape of msk: {msk.shape}\")\n",
    "        \n",
    "    #     loss = criteria(msk_pred, msk)\n",
    "    #     loss_boundary = criteria(B, boundary)\n",
    "    #     tloss    = (0.8*(loss)) + (0.2*loss_boundary) \n",
    "    #     optimizer.zero_grad()\n",
    "    #     tloss.backward()\n",
    "    #     epoch_loss += tloss.item()\n",
    "    #     optimizer.step()  \n",
    "    #     if (itter+1)%int(float(config['progress_p']) * len(train_loader)) == 0:\n",
    "    #         lr = optimizer.state_dict()['param_groups'][0]['lr']\n",
    "    #         print(f' Epoch>> {ep+1} and itteration {itter+1} loss>>{epoch_loss/(itter+1)}')\n",
    "    #     if (itter+1)*int(config['batch_size_tr']) == len(train_dataset):\n",
    "    #         visualizer.print_current_losses(epoch=(ep+1), iters=(itter+1), loss=((epoch_loss/(itter+1))), lr=lr, isVal=False)\n",
    "\n",
    "\n",
    "    # eval        \n",
    "    with torch.no_grad():\n",
    "        print('val_mode')\n",
    "        val_loss = 0\n",
    "        Net.eval()\n",
    "        for itter, batch in enumerate(val_loader):\n",
    "            img = batch['image'].to(device, dtype=torch.float)\n",
    "            msk = batch['mask'].to(device)\n",
    "            mask_type = torch.float32 if Net.n_classes == 1 else torch.long\n",
    "            msk = msk.to(device=device, dtype=mask_type)\n",
    "            msk_pred, B = Net(img)\n",
    "            if msk.shape[1] == 1:\n",
    "                msk = msk.squeeze(1)  # Remove channel dimension if it's 1\n",
    "            # Print shapes of predictions and ground truth\n",
    "            # print(f\"Shape of msk_pred: {msk_pred.shape}\")\n",
    "            # print(f\"Shape of msk: {msk.shape}\")\n",
    "            loss = criteria(msk_pred, msk)\n",
    "            val_loss += loss.item()\n",
    "        visualizer.print_current_losses(epoch=ep+1, loss=(abs(val_loss/(itter+1))), isVal=True)   \n",
    "        mean_val_loss = (val_loss/(itter+1))\n",
    "        # Check the performance and save the model\n",
    "        if mean_val_loss < best_val_loss:\n",
    "            best = ep + 1\n",
    "            best_val_loss = copy.deepcopy(mean_val_loss)\n",
    "            print('New best loss, saving...,best_val_loss=%6f' % (best_val_loss))\n",
    "            with open(log_name, \"a\") as log_file:\n",
    "                message = 'New best loss, saving...,best_val_loss=%6f' % (best_val_loss)\n",
    "                log_file.write('%s\\n' % message)\n",
    "            state = copy.deepcopy({'model_weights': Net.state_dict(), 'val_loss': best_val_loss})\n",
    "            torch.save(state, config['saved_model'])\n",
    "\n",
    "    scheduler.step(mean_val_loss)\n",
    "\n",
    "    if ep+1 == int(config['epochs']): \n",
    "        visualizer.print_end(best, best_val_loss)\n",
    "        state = copy.deepcopy({'model_weights': Net.state_dict(), 'val_loss': best_val_loss})\n",
    "        torch.save(state, config['saved_model_final'])\n",
    "\n",
    "print('Trainig phase finished')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cv_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
