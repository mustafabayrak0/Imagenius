{
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.13",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [
        {
          "sourceId": 8486285,
          "sourceType": "datasetVersion",
          "datasetId": 5062385
        }
      ],
      "dockerImageVersionId": 30699,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "accelerator": "GPU"
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mustafabayrak0/Imagenius/blob/main/comvis_DeepCrack_UNet.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import sys\n",
        "from pathlib import Path\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import matplotlib.pyplot as plt\n",
        "import datetime"
      ],
      "metadata": {
        "id": "w7HBLxVvW3Uz",
        "execution": {
          "iopub.status.busy": "2024-05-22T12:37:34.352494Z",
          "iopub.execute_input": "2024-05-22T12:37:34.353321Z",
          "iopub.status.idle": "2024-05-22T12:37:34.359803Z",
          "shell.execute_reply.started": "2024-05-22T12:37:34.353285Z",
          "shell.execute_reply": "2024-05-22T12:37:34.358918Z"
        },
        "trusted": true
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Set the working directory to the project folder\n",
        "project_path = '/content/drive/MyDrive/Main'\n",
        "os.chdir(project_path)\n",
        "\n",
        "# Add the project directory to the Python path\n",
        "sys.path.append(project_path)\n",
        "\n",
        "# Assuming config is defined somewhere, replace this with actual paths\n",
        "data_tra_path = '/content/drive/MyDrive/Main/DeepCrack/train'  # Replace with your actual path\n",
        "data_val_path = '/content/drive/MyDrive/Main/DeepCrack/test'    # Replace with your actual path\n",
        "\n",
        "DIR_IMG_tra = os.path.join(data_tra_path, 'images')\n",
        "DIR_MASK_tra = os.path.join(data_tra_path, 'masks')\n",
        "DIR_IMG_val = os.path.join(data_val_path, 'images')\n",
        "DIR_MASK_val = os.path.join(data_val_path, 'masks')\n",
        "\n",
        "img_names_tra = [path.name for path in Path(DIR_IMG_tra).glob('*.jpg')]\n",
        "mask_names_tra = [path.name for path in Path(DIR_MASK_tra).glob('*.png')]\n",
        "img_names_val = [path.name for path in Path(DIR_IMG_val).glob('*.jpg')]\n",
        "mask_names_val = [path.name for path in Path(DIR_MASK_val).glob('*.png')]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jAfLWXZ5NuBz",
        "outputId": "288c4bfe-64e7-4380-b2d5-3a9c4697c678",
        "execution": {
          "iopub.status.busy": "2024-05-22T12:37:34.361577Z",
          "iopub.execute_input": "2024-05-22T12:37:34.361868Z",
          "iopub.status.idle": "2024-05-22T12:37:34.374788Z",
          "shell.execute_reply.started": "2024-05-22T12:37:34.361844Z",
          "shell.execute_reply": "2024-05-22T12:37:34.373952Z"
        },
        "trusted": true
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def load_images_and_masks(img_dir, mask_dir):\n",
        "    img_names = sorted(os.listdir(img_dir))  # Ensure the list is sorted\n",
        "    mask_names = sorted(os.listdir(mask_dir))  # Ensure the list is sorted\n",
        "\n",
        "    images = []\n",
        "    masks = []\n",
        "    i = 0\n",
        "    for img_name, mask_name in zip(img_names, mask_names):\n",
        "        img_path = os.path.join(img_dir, img_name)\n",
        "        mask_path = os.path.join(mask_dir, mask_name)\n",
        "\n",
        "        image = Image.open(img_path).convert(\"RGB\")\n",
        "        mask = Image.open(mask_path).convert(\"L\")\n",
        "\n",
        "        images.append(np.array(image))\n",
        "        mask = np.array(mask) / 255.0  # Normalize mask to [0, 1]\n",
        "        masks.append(mask)\n",
        "        i += 1\n",
        "        if i == 10:\n",
        "            break\n",
        "\n",
        "    return images, masks\n",
        "\n",
        "# Directories\n",
        "DIR_IMG_tra = '/content/drive/MyDrive/Main/DeepCrack/train/images'\n",
        "DIR_MASK_tra = '/content/drive/MyDrive/Main/DeepCrack/train/masks'\n",
        "DIR_IMG_val = '/content/drive/MyDrive/Main/DeepCrack/test/images'\n",
        "DIR_MASK_val = '/content/drive/MyDrive/Main/DeepCrack/test/masks'\n",
        "\n",
        "# Load training and validation images and masks\n",
        "train_images, train_masks = load_images_and_masks(DIR_IMG_tra, DIR_MASK_tra)\n",
        "val_images, val_masks = load_images_and_masks(DIR_IMG_val, DIR_MASK_val)\n",
        "\n",
        "# Print the shapes to verify\n",
        "print(f'Loaded {len(train_images)} training images and {len(train_masks)} training masks.')\n",
        "print(f'Loaded {len(val_images)} validation images and {len(val_masks)} validation masks.')"
      ],
      "metadata": {
        "id": "9YOiUU4xYs5s",
        "execution": {
          "iopub.status.busy": "2024-05-22T12:37:34.399552Z",
          "iopub.execute_input": "2024-05-22T12:37:34.400084Z",
          "iopub.status.idle": "2024-05-22T12:37:37.224274Z",
          "shell.execute_reply.started": "2024-05-22T12:37:34.400051Z",
          "shell.execute_reply": "2024-05-22T12:37:37.223324Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "913ba87f-fae3-4c4a-b095-d7864a2568c7"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded 10 training images and 10 training masks.\n",
            "Loaded 10 validation images and 10 validation masks.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "# Verify image and mask pairs to ensure they are correctly aligned\n",
        "def verify_image_mask_pairs(images, masks, num_pairs=5):\n",
        "    fig, axs = plt.subplots(num_pairs, 2, figsize=(10, 5 * num_pairs))\n",
        "\n",
        "    for i in range(num_pairs):\n",
        "        img = images[i]\n",
        "        mask = masks[i]\n",
        "\n",
        "        axs[i, 0].imshow(img)\n",
        "        axs[i, 0].set_title('Image')\n",
        "        axs[i, 0].axis('off')\n",
        "\n",
        "        axs[i, 1].imshow(mask, cmap='gray')\n",
        "        axs[i, 1].set_title('Mask')\n",
        "        axs[i, 1].axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Verify the first few pairs of images and masks\n",
        "verify_image_mask_pairs(train_images, train_masks, num_pairs=5)\n",
        "\"\"\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 120
        },
        "id": "GXlp0pDtiQR2",
        "outputId": "4f31211a-c4cc-4e7b-9593-38d840b566b1"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\n# Verify image and mask pairs to ensure they are correctly aligned\\ndef verify_image_mask_pairs(images, masks, num_pairs=5):\\n    fig, axs = plt.subplots(num_pairs, 2, figsize=(10, 5 * num_pairs))\\n\\n    for i in range(num_pairs):\\n        img = images[i]\\n        mask = masks[i]\\n\\n        axs[i, 0].imshow(img)\\n        axs[i, 0].set_title('Image')\\n        axs[i, 0].axis('off')\\n\\n        axs[i, 1].imshow(mask, cmap='gray')\\n        axs[i, 1].set_title('Mask')\\n        axs[i, 1].axis('off')\\n\\n    plt.tight_layout()\\n    plt.show()\\n\\n# Verify the first few pairs of images and masks\\nverify_image_mask_pairs(train_images, train_masks, num_pairs=5)\\n\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class PatchCrackSegmentationDataset(Dataset):\n",
        "    def __init__(self, images, masks, transform=None):\n",
        "        self.images = images\n",
        "        self.masks = masks\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.images)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image = self.images[idx]\n",
        "        mask = self.masks[idx]\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "            mask = torch.tensor(mask, dtype=torch.float32).unsqueeze(0)\n",
        "\n",
        "        return image, mask\n",
        "\n",
        "# Define transformations (if any)\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "# Create dataset instances for training and validation data using patches\n",
        "train_patch_dataset = PatchCrackSegmentationDataset(train_images, train_masks, transform=transform)\n",
        "val_patch_dataset = PatchCrackSegmentationDataset(val_images, val_masks, transform=transform)\n",
        "\n",
        "# Create data loaders\n",
        "patch_batch_size = 2  # Adjust batch size as needed\n",
        "\n",
        "train_patch_loader = DataLoader(train_patch_dataset, batch_size=patch_batch_size, shuffle=True)\n",
        "val_patch_loader = DataLoader(val_patch_dataset, batch_size=patch_batch_size, shuffle=False)\n",
        "\n",
        "# Print the number of batches\n",
        "print(f'Number of training batches with patches: {len(train_patch_loader)}')\n",
        "print(f'Number of validation batches with patches: {len(val_patch_loader)}')\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-22T12:37:37.268095Z",
          "iopub.execute_input": "2024-05-22T12:37:37.268428Z",
          "iopub.status.idle": "2024-05-22T12:37:37.283240Z",
          "shell.execute_reply.started": "2024-05-22T12:37:37.268396Z",
          "shell.execute_reply": "2024-05-22T12:37:37.282340Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bjwfTdDGUD3K",
        "outputId": "ef7aba7d-aec1-4856-df9b-9b288e846f81"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of training batches with patches: 5\n",
            "Number of validation batches with patches: 5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class UNet(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(UNet, self).__init__()\n",
        "        self.in_channels = in_channels\n",
        "        self.out_channels = out_channels\n",
        "\n",
        "        # Max pooling operation\n",
        "        self.max_pool_2x2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "        # Downsampling phase\n",
        "        self.down_1 = self.double_conv(in_channels, 64)\n",
        "        self.down_2 = self.double_conv(64, 128, 0.2)\n",
        "        self.down_3 = self.double_conv(128, 256, 0.2)\n",
        "        self.down_4 = self.double_conv(256, 512, 0.2)\n",
        "        self.down_5 = self.double_conv(512, 1024)\n",
        "\n",
        "        # Upsampling phase\n",
        "        self.up_trans_1 = self.up_trans(1024, 512)\n",
        "        self.up_1 = self.double_conv(1024, 512)\n",
        "\n",
        "        self.up_trans_2 = self.up_trans(512, 256)\n",
        "        self.up_2 = self.double_conv(512, 256, 0.5)\n",
        "\n",
        "        self.up_trans_3 = self.up_trans(256, 128)\n",
        "        self.up_3 = self.double_conv(256, 128, 0.5)\n",
        "\n",
        "        self.up_trans_4 = self.up_trans(128, 64)\n",
        "        self.up_4 = self.double_conv(128, 64, 0.5)\n",
        "\n",
        "        # Output convolution\n",
        "        self.out = nn.Conv2d(64, out_channels, kernel_size=1)\n",
        "\n",
        "    def double_conv(self, in_channels, out_channels, dropout_p=0):\n",
        "        \"\"\"Double convolution (each followed by a batch normalization and a ReLU)\"\"\"\n",
        "        return nn.Sequential(\n",
        "            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1, padding_mode='reflect'),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(dropout_p),\n",
        "            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1, padding_mode='reflect'),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "            nn.ReLU(inplace=True),\n",
        "        )\n",
        "\n",
        "    def up_trans(self, in_channels, out_channels):\n",
        "        \"\"\"Upsampling operation\"\"\"\n",
        "        return nn.ConvTranspose2d(in_channels, out_channels, kernel_size=2, stride=2)\n",
        "\n",
        "    def forward(self, input):\n",
        "        down_x1 = self.down_1(input)\n",
        "        down_x2 = self.down_2(self.max_pool_2x2(down_x1))\n",
        "        down_x3 = self.down_3(self.max_pool_2x2(down_x2))\n",
        "        down_x4 = self.down_4(self.max_pool_2x2(down_x3))\n",
        "        down_x5 = self.down_5(self.max_pool_2x2(down_x4))\n",
        "\n",
        "        x = self.up_trans_1(down_x5)\n",
        "        x = self.up_1(torch.cat([down_x4, x], dim=1))\n",
        "\n",
        "        x = self.up_trans_2(x)\n",
        "        x = self.up_2(torch.cat([down_x3, x], dim=1))\n",
        "\n",
        "        x = self.up_trans_3(x)\n",
        "        x = self.up_3(torch.cat([down_x2, x], dim=1))\n",
        "\n",
        "        x = self.up_trans_4(x)\n",
        "        x = self.up_4(torch.cat([down_x1, x], dim=1))\n",
        "\n",
        "        x = self.out(x)\n",
        "\n",
        "        return x"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2024-05-22T12:37:37.284263Z",
          "iopub.execute_input": "2024-05-22T12:37:37.284573Z",
          "iopub.status.idle": "2024-05-22T12:37:37.298155Z",
          "shell.execute_reply.started": "2024-05-22T12:37:37.284534Z",
          "shell.execute_reply": "2024-05-22T12:37:37.297188Z"
        },
        "trusted": true,
        "id": "vsJDoPgMUD3L"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def pixel_level_accuracy(y_true, y_pred):\n",
        "    \"\"\"\n",
        "    Calculate the pixel-level accuracy between the ground truth mask and the predicted mask.\n",
        "\n",
        "    Args:\n",
        "    y_true (numpy.ndarray): Ground truth mask.\n",
        "    y_pred (numpy.ndarray): Predicted mask.\n",
        "\n",
        "    Returns:\n",
        "    float: Pixel-level accuracy.\n",
        "    \"\"\"\n",
        "    assert y_true.shape == y_pred.shape, \"The shape of the ground truth and predicted masks must match.\"\n",
        "\n",
        "    y_true = y_true.flatten()\n",
        "    y_pred = y_pred.flatten()\n",
        "\n",
        "    correct = np.sum(y_true == y_pred)\n",
        "    total = len(y_true)\n",
        "\n",
        "    accuracy = correct / total\n",
        "    return accuracy"
      ],
      "metadata": {
        "id": "8LqhvJqqduQY"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training function\n",
        "def train_patch_model(model, dataloader, criterion, optimizer, num_epochs=25):\n",
        "    model.train()\n",
        "    train_losses = []\n",
        "    current_date = datetime.datetime.now().strftime(\"%Y-%m-%d\")\n",
        "    for epoch in range(num_epochs):\n",
        "        running_loss = 0.0\n",
        "        for inputs, masks in dataloader:\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            # Check for shape mismatch\n",
        "            if outputs.shape != masks.shape:\n",
        "                print(f\"Shape mismatch: outputs {outputs.shape}, masks {masks.shape}\")\n",
        "                masks = F.interpolate(masks, size=outputs.shape[2:], mode='nearest')\n",
        "            loss = criterion(outputs, masks)\n",
        "            if loss.item() < 0:\n",
        "                print(f\"Negative loss detected: {loss.item()}\")\n",
        "                print(f\"Outputs: {outputs}\")\n",
        "                print(f\"Masks: {masks}\")\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            running_loss += loss.item() * inputs.size(0)\n",
        "        drive_save_path = f'/content/drive/MyDrive/Model-Weights/{current_date}-last-unet_model_weights-epoch:{epoch+1}.pth'\n",
        "        torch.save(model.state_dict(), drive_save_path)\n",
        "\n",
        "        epoch_loss = running_loss / len(dataloader.dataset)\n",
        "        train_losses.append(epoch_loss)\n",
        "        print(f'Epoch {epoch+1}/{num_epochs}, Loss: {epoch_loss:.4f}')\n",
        "\n",
        "    # Get current date\n",
        "    drive_save_path = f'/content/drive/MyDrive/last-unet_model_weights-{current_date}.pth'\n",
        "    torch.save(model.state_dict(), drive_save_path)\n",
        "\n",
        "    return model, train_losses\n",
        "\n",
        "\n",
        "# Evaluation function with pixel-level accuracy\n",
        "def evaluate_patch_model_with_accuracy(model, dataloader, criterion):\n",
        "    model.eval()\n",
        "    val_loss = 0.0\n",
        "    total_accuracy = 0.0\n",
        "    num_samples = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, masks in dataloader:\n",
        "            outputs = model(inputs)\n",
        "            # Check for shape mismatch\n",
        "            if outputs.shape != masks.shape:\n",
        "                print(f\"Shape mismatch: outputs {outputs.shape}, masks {masks.shape}\")\n",
        "                # Resize masks to match outputs if necessary\n",
        "                masks = F.interpolate(masks, size=outputs.shape[2:], mode='nearest')\n",
        "            loss = criterion(outputs, masks)\n",
        "            val_loss += loss.item() * inputs.size(0)\n",
        "\n",
        "            outputs = torch.sigmoid(outputs)\n",
        "            outputs = (outputs > 0.5).float()\n",
        "\n",
        "            outputs = outputs.cpu().numpy()\n",
        "            masks = masks.cpu().numpy()\n",
        "\n",
        "            for i in range(len(outputs)):\n",
        "                accuracy = pixel_level_accuracy(masks[i], outputs[i])\n",
        "                total_accuracy += accuracy\n",
        "                num_samples += 1\n",
        "\n",
        "    val_loss /= num_samples\n",
        "    avg_accuracy = total_accuracy / num_samples\n",
        "    print(f'Validation Loss: {val_loss:.4f}')\n",
        "    print(f'Average Pixel-level Accuracy: {avg_accuracy:.4f}')\n",
        "    return val_loss, avg_accuracy\n",
        "\n",
        "model = UNet(in_channels = 3, out_channels= 1)\n",
        "# Define loss function and optimizer\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Train the model with patches and capture loss history\n",
        "num_epochs = 5\n",
        "trained_patch_model, train_losses = train_patch_model(model, train_patch_loader, criterion, optimizer, num_epochs=num_epochs)\n",
        "\n",
        "# Evaluate the model with patches and capture validation loss and accuracy\n",
        "val_loss, avg_accuracy = evaluate_patch_model_with_accuracy(trained_patch_model, val_patch_loader, criterion)"
      ],
      "metadata": {
        "id": "90NpvuWDYlgz",
        "execution": {
          "iopub.status.busy": "2024-05-22T12:37:38.069704Z",
          "iopub.execute_input": "2024-05-22T12:37:38.070175Z"
        },
        "trusted": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot training and validation loss\n",
        "def plot_loss_curves(train_losses, val_loss):\n",
        "    epochs = range(1, len(train_losses) + 1)\n",
        "    plt.figure(figsize=(10, 5))\n",
        "    plt.plot(epochs, train_losses, label='Training Loss')\n",
        "    plt.axhline(y=val_loss, color='r', linestyle='-', label='Validation Loss')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "    plt.title('Training and Validation Loss')\n",
        "    plt.show()\n",
        "\n",
        "# Plot the loss curves\n",
        "plot_loss_curves(train_losses, val_loss)\n"
      ],
      "metadata": {
        "id": "reSvLZFFZNrK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize first image in the train data\n",
        "image, mask = train_patch_dataset[0]\n",
        "plt.imshow(image.permute(1, 2, 0))\n",
        "plt.title('Image')\n",
        "plt.show()\n",
        "plt.imshow(mask.squeeze(), cmap='gray')\n",
        "plt.title('Mask')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "cQE5nHEilKvX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to predict and visualize samples\n",
        "def predict_and_visualize(model, dataset, num_samples=5):\n",
        "    model.eval()\n",
        "    indices = np.random.choice(len(dataset), num_samples, replace=False)\n",
        "    fig, axs = plt.subplots(num_samples, 3, figsize=(15, 5 * num_samples))\n",
        "\n",
        "    for i, idx in enumerate(indices):\n",
        "        image_patch, mask_patch = dataset[idx]\n",
        "        with torch.no_grad():\n",
        "            output = model(image_patch.unsqueeze(0)).squeeze(0)\n",
        "            output = torch.sigmoid(output)\n",
        "            output = (output > 0.5).float()\n",
        "\n",
        "        axs[i, 0].imshow(image_patch.permute(1, 2, 0))\n",
        "        axs[i, 0].set_title('Input Image')\n",
        "        axs[i, 1].imshow(mask_patch.squeeze(), cmap='gray')\n",
        "        axs[i, 1].set_title('Ground Truth Mask')\n",
        "        axs[i, 2].imshow(output.squeeze(), cmap='gray')\n",
        "        axs[i, 2].set_title('Predicted Mask')\n",
        "\n",
        "        for ax in axs[i]:\n",
        "            ax.axis('off')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# Predict and visualize samples from the validation dataset\n",
        "predict_and_visualize(trained_patch_model, val_patch_dataset, num_samples=5)\n"
      ],
      "metadata": {
        "id": "4wi6cyqsZP0a"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}