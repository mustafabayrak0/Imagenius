{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import argparse\n",
    "import codecs\n",
    "import yaml\n",
    "from tqdm import tqdm\n",
    "from newloader import *\n",
    "from pathlib import Path\n",
    "from matplotlib import pyplot as plt\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from model.TransMUNet import TransMUNet\n",
    "from utils.utils import get_img_patches, merge_pred_patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = \"\"\n",
    "thresh_step = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_prf_metrics(pred_list, gt_list, thresh_step=0.01):\n",
    "    final_accuracy_all = []\n",
    "\n",
    "    for thresh in np.arange(0.0, 1.0, thresh_step):\n",
    "        # print(thresh)\n",
    "        statistics = []\n",
    "        \n",
    "        for pred, gt in zip(pred_list, gt_list):\n",
    "            gt_img   = (gt).astype('uint8')\n",
    "            pred_img = (pred > thresh).astype('uint8')\n",
    "            # calculate each image\n",
    "            statistics.append(get_statistics(pred_img, gt_img))\n",
    "        \n",
    "        # get tp, fp, fn\n",
    "        tp = np.sum([v[0] for v in statistics])\n",
    "        fp = np.sum([v[1] for v in statistics])\n",
    "        fn = np.sum([v[2] for v in statistics])\n",
    "\n",
    "        # calculate precision\n",
    "        p_acc = 1.0 if tp==0 and fp==0 else tp/(tp+fp)\n",
    "        # calculate recall\n",
    "        r_acc = tp/(tp+fn)\n",
    "        # calculate f-score\n",
    "        final_accuracy_all.append([thresh, p_acc, r_acc, 2*p_acc*r_acc/(p_acc+r_acc)])\n",
    "    return final_accuracy_all\n",
    "\n",
    "def get_statistics(pred, gt):\n",
    "    \"\"\"\n",
    "    return tp, fp, fn\n",
    "    \"\"\"\n",
    "    tp = np.sum((pred==1)&(gt==1))\n",
    "    fp = np.sum((pred==1)&(gt==0))\n",
    "    fn = np.sum((pred==0)&(gt==1))\n",
    "    return [tp, fp, fn]\n",
    "\n",
    "def save_results(input_list, output_path):\n",
    "    with codecs.open(output_path, 'w', encoding='utf-8') as fout:\n",
    "        for ll in input_list:\n",
    "            line = '\\t'.join(['%.4f'%v for v in ll])+'\\n'\n",
    "            fout.write(line)\n",
    "\n",
    "def save_sample(img_path, msk, msk_pred, name=''):\n",
    "    img = cv2.imread(img_path)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    msk = msk.astype(int)\n",
    "    mskp = msk_pred\n",
    "    _, axs = plt.subplots(1, 3, figsize=(15,5))\n",
    "    axs = axs.ravel()\n",
    "\n",
    "    axs[0].axis('off')\n",
    "    axs[0].imshow(img/255.)\n",
    "    axs[0].set_title('Original Image')\n",
    "    # Set size of the title\n",
    "    axs[0].title.set_size(30)\n",
    "\n",
    "    axs[1].axis('off')\n",
    "    axs[1].imshow(msk*255, cmap= 'gray')\n",
    "    axs[1].set_title('Ground Truth Mask')\n",
    "    axs[1].title.set_size(30)\n",
    "    \n",
    "\n",
    "    axs[2].axis('off')\n",
    "    axs[2].imshow(mskp*255, cmap= 'gray')\n",
    "    axs[2].set_title('Predicted Mask')\n",
    "    axs[2].title.set_size(30)\n",
    "\n",
    "    plt.savefig(config['save_result'] + name + '.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config         = yaml.load(open('./config_crack.yml'), Loader=yaml.FullLoader)\n",
    "number_classes = int(config['number_classes'])\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = config['path_to_testdata']\n",
    "DIR_IMG  = os.path.join(data_path, 'images2')\n",
    "DIR_MASK = os.path.join(data_path, 'masks2')\n",
    "img_names  = [path.name for path in Path(DIR_IMG).glob('*.jpg')]\n",
    "mask_names = [path.name for path in Path(DIR_MASK).glob('*.png')]\n",
    "\n",
    "test_dataset = Crack_loader(img_dir=DIR_IMG, img_fnames=img_names, mask_dir=DIR_MASK, mask_fnames=mask_names)\n",
    "test_loader  = DataLoader(test_dataset, batch_size = 1, shuffle= False)\n",
    "print(f'test_dataset:{len(test_dataset)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Net = TransMUNet(n_classes = number_classes)\n",
    "Net = Net.to(device)\n",
    "Net.load_state_dict(torch.load(config['saved_model'], map_location='cpu')['model_weights'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_list = []\n",
    "gt_list = []\n",
    "save_samples = True # if save_samples=Flase, no samples will be saved.\n",
    "\n",
    "with torch.no_grad():\n",
    "    print('val_mode')\n",
    "    val_loss = 0\n",
    "    times =0\n",
    "    Net.eval()\n",
    "\n",
    "    for itter, batch in enumerate(tqdm(test_loader)):\n",
    "        img = batch['image'].numpy().squeeze(0)\n",
    "        img_path = batch['img_path'][0]\n",
    "        msk = batch['mask']\n",
    "        patch_totensor = ImgToTensor()\n",
    "        preds = []\n",
    "            \n",
    "        start = time.time()\n",
    "        patches, patch_locs = get_img_patches(img)\n",
    "        for i, patch in enumerate(patches):\n",
    "            patch_n = patch_totensor(Image.fromarray(patch))         # torch.Size([3, 256, 256])\n",
    "            X = (patch_n.unsqueeze(0)).to(device, dtype=torch.float) # torch.Size([1, 3, 256, 256])\n",
    "            msk_pred = torch.sigmoid(Net(X))                         # torch.Size([1, 1, 256, 256])\n",
    "            mask = msk_pred.cpu().detach().numpy()[0, 0]             # (256, 256)\n",
    "            preds.append(mask)\n",
    "        mskp = merge_pred_patches(img, preds, patch_locs)            # (H, W)\n",
    "        kernel = np.array(\n",
    "                [\n",
    "                    [0, 0, 1, 0, 0],\n",
    "                    [0, 1, 1, 1, 0],\n",
    "                    [1, 1, 1, 1, 1],\n",
    "                    [0, 1, 1, 1, 0],\n",
    "                    [0, 0, 1, 0, 0],\n",
    "                ], dtype=np.uint8)\n",
    "        mskp = cv2.morphologyEx(mskp, cv2.MORPH_CLOSE, kernel,iterations=1).astype(float)\n",
    "        end = time.time()\n",
    "        times += (end - start)\n",
    "        if itter < 237 and save_samples:\n",
    "            save_sample(img_path, msk.numpy()[0, 0], mskp, name=str(itter+1))\n",
    "\n",
    "        gt_list.append(msk.numpy()[0, 0])\n",
    "        pred_list.append(mskp)\n",
    "    print('Running time of each images: %ss' % (times/len(pred_list)))\n",
    "\n",
    "final_results = []\n",
    "final_results = cal_prf_metrics(pred_list, gt_list, thresh_step)\n",
    "save_results(final_results, output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cv_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
